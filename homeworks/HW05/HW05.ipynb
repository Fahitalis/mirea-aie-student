{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582fe586",
   "metadata": {},
   "source": [
    "# HW05: базовый ML-пайплайн с логистической регрессией и сравнение с бейзлайном\n",
    "\n",
    "Домашнее задание: загрузка данных, базовая разведка, подготовка признаков, бейзлайн через `DummyClassifier`, логистическая регрессия с подбором `C`, сравнение метрик и краткие выводы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d77d5",
   "metadata": {},
   "source": [
    "## 2.3.1. Загрузка данных и первичный анализ\n",
    "\n",
    "Импортируем библиотеки, читаем S05-hw-dataset.csv и смотрим базовые характеристики датасета: размер, типы столбцов, описательные статистики и баланс таргета `default`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7525385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "DATA_PATH = Path(\"S05-hw-dataset.csv\")\n",
    "FIGURES_DIR = Path(\"figures/\")\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Датасет загружен из {DATA_PATH}\")\n",
    "print(f\"Размер: {df.shape[0]} объектов, {df.shape[1]} столбцов\")\n",
    "\n",
    "display(df.head())\n",
    "print(\"\\nИнформация о столбцах:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nОписательные статистики (числовые фичи):\")\n",
    "display(df.describe().T)\n",
    "\n",
    "print(\"\\nБаланс таргета default:\")\n",
    "value_counts = df[\"default\"].value_counts()\n",
    "value_share = df[\"default\"].value_counts(normalize=True)\n",
    "display(pd.DataFrame({\"count\": value_counts, \"share\": value_share}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26113bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "non_numeric_cols = [col for col in df.columns if not pd.api.types.is_numeric_dtype(df[col])]\n",
    "debt_bounds = df[\"debt_to_income\"].agg([\"min\", \"max\"])\n",
    "neg_savings = int((df[\"savings_balance\"] < 0).sum())\n",
    "neg_checking = int((df[\"checking_balance\"] < 0).sum())\n",
    "\n",
    "print(f\"Количество объектов: {n_rows}, число столбцов (включая таргет): {n_cols}\")\n",
    "print(f\"Ненумерических столбцов: {len(non_numeric_cols)} -> {non_numeric_cols}\")\n",
    "print(f\"Диапазон debt_to_income: min={debt_bounds['min']:.4f}, max={debt_bounds['max']:.4f}\")\n",
    "print(f\"Отрицательные значения в savings_balance: {neg_savings}\")\n",
    "print(f\"Отрицательные значения в checking_balance: {neg_checking}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df[\"default\"].value_counts().to_dict()\n",
    "target_share = df[\"default\"].value_counts(normalize=True).to_dict()\n",
    "summary_text = f\"\"\"\n",
    "**Краткие наблюдения**\n",
    "- В выборке {n_rows} объектов и {n_cols - 1} признаков после исключения таргета.\n",
    "- Все столбцы числовые, дополнительная кодировка категорий не требуется.\n",
    "- Диапазон `debt_to_income` лежит в [{debt_bounds['min']:.3f}; {debt_bounds['max']:.3f}], выглядит допустимо.\n",
    "- Отрицательные остатки: savings_balance={neg_savings}, checking_balance={neg_checking}; можно считать это допустимыми овердрафтами, явных аномалий не видно.\n",
    "- Баланс классов: default=0 — {target_counts.get(0, 0)} ({target_share.get(0, 0):.3f}), default=1 — {target_counts.get(1, 0)} ({target_share.get(1, 0):.3f}).\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e985f5",
   "metadata": {},
   "source": [
    "## 2.3.2. Подготовка признаков и таргета\n",
    "\n",
    "Таргет — столбец `default`. В качестве признаков используем все остальные столбцы, исключая `client_id`. Проверим, что признаки числовые, и контролируем диапазон `debt_to_income`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.columns.drop([\"default\", \"client_id\"])\n",
    "X = df[feature_cols]\n",
    "y = df[\"default\"]\n",
    "\n",
    "non_numeric_after = [col for col in X.columns if not pd.api.types.is_numeric_dtype(X[col])]\n",
    "debt_ok_share = ((X[\"debt_to_income\"] >= 0) & (X[\"debt_to_income\"] <= 1)).mean()\n",
    "\n",
    "print(f\"Признаков в X: {X.shape[1]}, объектов: {X.shape[0]}\")\n",
    "print(f\"Ненумерические признаки: {non_numeric_after}\")\n",
    "print(f\"Доля объектов с debt_to_income в [0,1]: {debt_ok_share:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c680ec5",
   "metadata": {},
   "source": [
    "## 2.3.3. Train/Test-сплит и бейзлайн-модель\n",
    "\n",
    "Делим данные на обучение/тест с стратификацией по таргету, строим `DummyClassifier` как точку отсчёта и считаем метрики accuracy и ROC-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train shape: {X_train.shape}, Test shape: {X_test.shape},\"\n",
    "    f\" positive share train={y_train.mean():.3f}, test={y_test.mean():.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f7208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "y_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "baseline_metrics = {\n",
    "    \"model\": \"DummyClassifier\",\n",
    "    \"accuracy\": metrics.accuracy_score(y_test, y_pred_dummy),\n",
    "    \"roc_auc\": metrics.roc_auc_score(y_test, y_proba_dummy),\n",
    "    \"precision\": metrics.precision_score(y_test, y_pred_dummy),\n",
    "    \"recall\": metrics.recall_score(y_test, y_pred_dummy),\n",
    "    \"f1\": metrics.f1_score(y_test, y_pred_dummy),\n",
    "}\n",
    "\n",
    "print(\"Бейзлайн (DummyClassifier, stratified):\")\n",
    "display(pd.DataFrame([baseline_metrics]))\n",
    "print(\"DummyClassifier просто имитирует распределение классов, выступая точкой отсчёта для более сложных моделей.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ef3e5",
   "metadata": {},
   "source": [
    "## 2.3.4. Логистическая регрессия и подбор гиперпараметров\n",
    "\n",
    "Строим конвейер StandardScaler → LogisticRegression, подбираем `C` через GridSearchCV и оцениваем лучшую модель по accuracy, ROC-AUC и дополнительным метрикам. Построим ROC-кривую и сохраним её в `homeworks/HW05/figures/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, solver=\"lbfgs\")),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"logreg__C\": [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=logreg_pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "print(f\"Лучшая модель по ROC-AUC на кросс-валидации: {grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fe350",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = best_model.predict(X_test)\n",
    "y_proba_lr = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "logreg_metrics = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"best_C\": grid.best_params_[\"logreg__C\"],\n",
    "    \"accuracy\": metrics.accuracy_score(y_test, y_pred_lr),\n",
    "    \"roc_auc\": metrics.roc_auc_score(y_test, y_proba_lr),\n",
    "    \"precision\": metrics.precision_score(y_test, y_pred_lr),\n",
    "    \"recall\": metrics.recall_score(y_test, y_pred_lr),\n",
    "    \"f1\": metrics.f1_score(y_test, y_pred_lr),\n",
    "}\n",
    "\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Метрики LogisticRegression (лучшая по GridSearchCV):\")\n",
    "display(pd.DataFrame([logreg_metrics]))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "display(pd.DataFrame(conf_mat, index=[\"true_0\", \"true_1\"], columns=[\"pred_0\", \"pred_1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b806977",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba_lr)\n",
    "roc_auc_lr = metrics.roc_auc_score(y_test, y_proba_lr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"LogReg (AUC={roc_auc_lr:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-кривая: Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "roc_path = FIGURES_DIR / \"roc_curve_logreg.png\"\n",
    "plt.savefig(roc_path, dpi=150)\n",
    "plt.show()\n",
    "print(f\"ROC-кривая сохранена в {roc_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a5e91",
   "metadata": {},
   "source": [
    "## 2.3.5. Сравнение моделей и текстовые выводы\n",
    "\n",
    "Сведём метрики бейзлайна и логистической регрессии, а затем сформулируем итоговые выводы по качеству и влиянию регуляризации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8008c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metrics.setdefault(\"best_C\", np.nan)\n",
    "results_df = pd.DataFrame([baseline_metrics, logreg_metrics])[\n",
    "    [\"model\", \"best_C\", \"accuracy\", \"roc_auc\", \"precision\", \"recall\", \"f1\"]\n",
    "]\n",
    "\n",
    "print(\"Сводная таблица метрик:\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_acc = logreg_metrics[\"accuracy\"] - baseline_metrics[\"accuracy\"]\n",
    "delta_auc = logreg_metrics[\"roc_auc\"] - baseline_metrics[\"roc_auc\"]\n",
    "\n",
    "summary_md = f\"\"\"\n",
    "**Итоговые выводы**\n",
    "1. Бейзлайн DummyClassifier (strategy=stratified) даёт accuracy {baseline_metrics['accuracy']:.3f} и ROC-AUC {baseline_metrics['roc_auc']:.3f}; метрики соответствуют случайным угадываниям, что ожидаемо.\n",
    "2. Логистическая регрессия с лучшим `C={logreg_metrics['best_C']}` показывает accuracy {logreg_metrics['accuracy']:.3f} и ROC-AUC {logreg_metrics['roc_auc']:.3f}, превосходя бейзлайн.\n",
    "3. Прирост accuracy = {delta_acc:.3f}, прирост ROC-AUC = {delta_auc:.3f}; выигрыш особенно заметен по AUC, что важно при несбалансированных классах.\n",
    "4. Значение `C={logreg_metrics['best_C']}` говорит, что модель предпочла {\"сильную\" if logreg_metrics['best_C'] < 1 else \"умеренную\" if logreg_metrics['best_C'] == 1 else \"более слабую\"} регуляризацию; слишком маленькие C ухудшали качество, слишком большие — не дали дополнительного выигрыша.\n",
    "5. Precision/recall {logreg_metrics['precision']:.3f}/{logreg_metrics['recall']:.3f} выше, чем у бейзлайна, а матрица ошибок показывает лучшее распознавание положительного класса.\n",
    "6. ROC-кривая логистической регрессии выше диагонали, файл сохранён в папке `homeworks/HW05/figures/` и подтверждает стабильное превосходство над случайным угадыванием.\n",
    "7. Для задачи кредитного скоринга логистическая регрессия выглядит разумным выбором: метрики лучше, интерпретируемость высокая, пайплайн простой и воспроизводимый.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary_md))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
